experiment_name: mathlm0-1.3B-math
task: "math"
model_load_path: "/fsx/mathlm0/proof-pile-1.3B-hf"
log_dir: "/fsx/mathlm0/math-lm-task-finetunes/runs"

max_length: 2048

lr: 2.e-5
lr_schedule: "cosine"
warmup_steps: 100
train_steps: 2000
log_steps: 100
save_steps: 1000
batch_size_per_device: 8 # want effective batch size of 32 across experiments
gradient_accumulation: 4
weight_decay: 0.01

